# 工作流引擎架构

## 工作流

AI 工作流（AI Workflow）是一种 AI 时代的新开发范式，它允许用户通过拖放节点并用边连接它们来创建复合 AI 能力。

### 设计目标

核心设计目标如下：

* 无代码和可视化：工作流引擎应该是可视化无代码的。普通用户只需要通过拖放节点并用边连接它们来创建复合 AI 能力。AI 工作流引擎应该是可调试的，用户可以在运行时查看节点的输入和输出，从而有机会调整合适的 AI 模型和方法以达到最佳效果。
* 可扩展性：AI 工作流引擎应该是可扩展的，可以轻松地添加新的节点和边。AI 工作流引擎应该是通用的，可以用于任何 AI 场景，包括但不限于文本、图像、视频、语音、自然语言处理、机器学习、深度学习、强化学习等。
* 客观中立：虽然平台会从便利使用的角度推荐缺省的各类供应商，但原则上使用者可以完全自由的选择其他供应商。如果特定的能力提供者尚未被接入，开发者可以自行开发节点并将其接入到平台中。
* 可聚合性：应用开发者可以将 AI 工作流当做一个干净的 API 进行调用，从而让自己的应用迅速具备 AI 能力。

## 数据结构

### 数据流转

为了让流引擎尽可能通用，我们需要定义流中流动的数据结构。 数据结构应该能够表示任何类型的数据，例如文本、JSON 对象、二进制文件等。

由于我们的关键场景是面向AIGC（人工智能生成内容），并且每个内容都可以简单地映射到一个文件（或者是一个 JSON）。 所以我们将使用文件作为流中流动的基本数据结构。 为了便于描述，我们将使用 JSON 作为顶层数据格式，以一致方式表达二进制文件、短文本或长文本或 JSON 对象。 基本结构如下：

```json
{
  "type": "text",
  "name": "test.txt",
  "description": "This is a test file",
  "format": "utf-8",
  "data": "This is a test file"
}
```

并非所有字段都是必需的，但“类型”和“数据”是必需的。 `type` 字段用于指示数据的类型，可以是以下之一：

* text（默认为 utf-8，或由 `format` 字段指定）
* json
* image（还需要指定`format`字段，比如png, jpg, gif等）

因此，每个端口都应包含相应的数据模式。 例如，一个文本分类器节点当然应该只将文本作为输入和输出文本。 该架构将与以下内容类似：

```json
{
  "type": "text",
  "conditions": {
    "minLength": "30",
    "maxLength": "4096",
  }
}
```

或图像：

```json
{
  "type": "image",
  "format": "png|jpg|webp",
  "conditions": {
    "dataFormat": "base64",
  }
}
```

这些只是用于解释目的的一些示例，而不是最终规范。 这些规则可以指导我们进行节点操作，例如确定我们是否可以将两个节点连接在一起。

### 逻辑控制

在运行流引擎时，我们当然需要支持基本的逻辑控制，比如if-else、switch-case、for-loop等。我们将使用如下JSON schema来表示逻辑控制：

```json
{
  "type": "if",
  "condition": "data.length > 100",
  "true": {
    "type": "node",
    "id": "node-1"
  },
  "false": {
    "type": "node",
    "id": "node-2"
  }
}
```

我们需要想出解决方案：是提供一套内置的逻辑控件，还是始终将逻辑集成在任务节点中？ 例如，对于文本分类器节点，我们可以提出一个是或否的问题作为提示，然后根据答案来确定下一步去哪个节点。 或者我们可以提供一个内置的 if-else 节点，然后根据结果来决定下一步去哪个节点。

前者更灵活方便，后者更简洁，更程序员方式。 现在，我们将选择前者。 挑战在于如何做出判断。 我们可以参考Waveline的案例：

![waveline-logic-control](https://waveline.ai/_next/static/media/workflow-example.58a6808d.svg)

从这个案例研究中，我们可能应该提供一组内置的逻辑控制，例如 if-else、switch-case、for-loop 等。我们还应该提供一种将逻辑集成到任务节点中的方法，例如 作为文本分类器节点。 这意味着我们需要提供必要的提示，使结果具有可解释性，并用结果触发不同的输出端口。

我们不建议用循环来让逻辑流程变得复杂，因为这样设计和实现起来都会很困难，所以我们会采用DAG方法。 但是，如果人们真的需要一种循环，我们可以提供一种方法来实现，比如提供一个中间件来存储结果，并以上次运行的结果作为输入重复触发流评估。

### 节点（Node）

每个节点都有以下关键属性：

* 唯一身份
* 名称，不要求唯一，仅供展示
* 描述，与名称相同，仅供展示
* 类型，以下之一：
   * 开始
   * 结尾
   * 行动
   * 健康）状况
   * 子流

   为了简化思考过程，让我们暂时关注 Action 节点。

* Template，用于渲染节点的模板，包括以下内容：
   * 输入端口，对于那些没有任何输入端口的触发节点，例如文件代理，这是可选的；
   * 输出端口，对于那些没有任何输出端口的动作节点，这也是可选的，例如Slack通知节点；
   * 属性字段，我们假设它是一个键值对列表

为了用户体验的目的，我们需要显示节点的状态，比如它是否正在运行，或者完成，或者失败等。所以我们需要添加以下字段：

* 状态，以下之一：
   * 就绪(Ready)
   * 执行(Running)
   * 等待输入(Waiting)，输入节点在交互式运行时会有这个状态
   * 完成(Completed)
   * 失败(Failed)

* 节点的执行进度，从0到100。因为 AI 任务通常比较费时间，因此这个信息也比较重要。

* 结果预览

   这个是可选的，只有在节点完成时才可用（比如一个文件代理节点，可以预览文件的内容，或者图片生成任务完成后，我们应该可以通过某种方式预览生成的图片 )

### 节点类型

从工作流的完备性的角度，节点可以被分为如下几类:

* 输入节点，比如加载一个文件，从一个 URL 抓取数据，向现有系统调用一个规格已知的 API 等，目的都是获取启动工作流所需要的数据；
* 任务节点，如上所述的对输入数据进行处理产生新的数据，具体可分为文本、图像、视频、数据等等；
* 输出节点，分为展示节点（直接可视化呈现），数据导出节点，可以对接现有的业务流程；

以上几种为一个工作流的必要组成部分，不过理论上如果只有一个输入节点也可以执行。除此之外还可以有如下几种：

* 逻辑控制节点，对节点的计算结果进行判断以控制工作流的走向；
* 辅助节点，比如一个 Debug 节点可以实时展示某个节点的运行结果；
* 扩展任务节点，可以运行一个特定的函数，作为对 AI 节点的补充，比如对文件内容进行预处理等。对于这种节点，Python 可能是最适合的语言；

![sample](https://cdn.sspai.com/2023/05/21/f9e2d99fde30a04e6553d0190575d1c8.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

### 连线（Edge）

根据定义，边是两个节点之间的连接，具有以下关键属性：

* 唯一身份
* 源节点ID
* Source handle ID，源节点输出端口的ID。 如果不指定，默认使用最新的
* 目标节点ID
* 连接类型，以下之一：Line、Bezier、Step
* Animated，边缘是否动画，默认为false

这些和react-flow中的定义基本一致。 当我们对此有更多想法时，我们将扩展文档。

### 工作流验证

每个工作流由若干节点和连线组成，并包含相应的配置信息。在执行前需要进行如下验证：

1. 是否有且只有一个触发器节点；
2. 触发器是否连接到一个无需依赖其他输入的下游节点，比如一个自身有设置数据源能力的输入节点（例如：文件加载节点）；

### 工作流发布为 API

工作流可以发布为 API，这样可以方便地被其他系统调用。 为了实现这个目标，我们需要定义以下内容：

1. API 的 URL，这个是必须的，原则上的结构为 `/api/flow/{org_id}/{flow_id}`；
2. API 的调用规格说明，显然的，这些文档需要自动生成。我们可以认为所有的请求只支持 POST，且参数与工作流中的输入节点规格对齐（包括输入和配置）；

## 执行实例

工作流的运行模式分为交互式和 API 方式两种。交互式是指在街面上点击运行按钮，然后等待工作流执行完成。API 方式是指将工作流发布为 API，然后通过调用 API 的方式执行工作流。

不过在内核层面，这两种方式是一致的，都通过执行实例来完成。

每个工作流在开始执行后，将创建一个工作流实例。 工作流实例是工作流的运行时表示，会包含以下关键数据：

1. 工作流级别的实例上下文数据（Context），例如工作流实例的执行时间，对应的工作流数据等。
2. 每一个节点的当前运行状态，如：就绪、运行中、完成、出错等。
3. 节点执行的上下文数据，即每一个节点的输入输出信息，将缓存到对应的端口。

原则上，工作流实例的执行是异步的，即工作流实例的创建和执行是分开的。这样可以避免工作流实例的创建和执行耦合在一起，从而提高系统的可扩展性。

每次执行的工作流实例可以选择保存全部执行痕迹或者只保留最终结果。我们可以将此自由度留给工作流的具体实现，以保留最终结果作为基础的执行记录内容之一，完整的执行记录包含如下内容：

* 工作流 ID
* 工作流实例 ID
* 工作流的执行者，即工作流实例的创建者，因为工作流可分享，所以工作流的执行者可能不是工作流的创建者
* 工作流实例创建时间，即开始执行时间
* 工作流实例结束时间（如果仍在执行，则此值为空）
* 工作流实例状态，如：就绪、运行中、完成、出错等
* 工作流实例的执行结果，即工作流实例的输出数据，对应到末端节点的输出端口
* 可选：工作流实例的执行痕迹，即工作流实例的执行过程，包括每个节点的执行状态、执行时间、执行结果等

## 其他

这个项目建立在 react-flow 之上，react-flow 是一个用于构建基于节点的编辑器和图表的 React 库。 所以我们从中借鉴了很多基本概念来简化我们的系统设计和实现，比如流、节点、边缘等。

参考项目：

* n8n
* Zapier
* https://huggingface.co/spaces/Logspace/LangFlow
* https://llmfarm.com
* https://vectorvein.com/ https://github.com/AndersonBY/vector-vein https://sspai.com/post/79916

